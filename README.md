### Extrapolation_of_regression

### Горшков Андрей Вячеславович
### Повышение точности экстраполяции регрессии путем учета погрешности измерения переменных
------------------------------------------

Рассмотрена задача экстраполяции регрессии для наборов данных с практически абсолютной мультиколлинеарностью всех предикторов. Предполагается, что предикторы и целевая переменная заданы с некоторыми известными погрешностями измерений.

На сгенерированных наборах данных обучены различные модели регрессоров из библиотеки Scikit-learn, модели двухслойных нейронных сетей прямого распространения и модель регуляризации Тихонова [1], коэффициент регуляризации которой определяется по условию оптимизации нестандартной (для Scikit-learn) метрики – обобщенной невязки, учитывающей информацию о погрешности измерения предикторов и целевой переменной.

Несмотря на отличные метрики (R2 ≈ 1) всех обученных моделей регрессоров из библиотеки Scikit-learn, результаты их прогнозов не только имеют неприемлемую точность, но и являются неустойчивыми – небольшие погрешности измерений данных приводят к недопустимым погрешностям прогноза целевой переменной (в терминологии ML это означает, что модели переобучаются). Разброс (variance) осредненного прогноза различных моделей регрессоров составил ±38% при смещении (bias) 7%.

При этом результаты прогнозов двухслойной нейронной сети прямого распространения являются достаточно устойчивыми и имеют приемлемую точность. Разброс (variance) прогноза составил ±6% при смещении (bias) 11%.

Наилучшие устойчивые прогнозы с приемлемой точностью выдает модель регуляризации Тихонова, учитывающая информацию о погрешности измерения предикторов и целевой переменной. Разброс (variance) прогноза модели регуляризации Тихонова составил ±0,2% при смещении (bias) 8%.

Выводы:
1. Игнорирование даже незначительной погрешности измерения значений предикторов и целевой переменной может привести к крайне большой погрешности прогноза экстраполяции регрессии.

2. Модели регрессоров Scikit-learn, обученные на наборах данных с мультиколлинеарными предикторами по условию оптимизации стандартных метрик Scikit-learn, могут привести к неустойчивым прогнозам экстраполяции с недопустимой погрешностью.

3. Для наборов данных с мультиколлинеарными предикторами для получения устойчивого прогноза экстраполяции с допустимой погрешностью следует использовать модель регуляризации Тихонова, учитывающую информацию о погрешности измерения предикторов и целевой переменной.
   
4. При отсутствии информации о погрешности измерения предикторов и целевой переменной следует использовать модели нейронных сетей прямого распространения с подбором оптимального числа нейронов на каждом слое по условию оптимизации стандартных метрик Scikit-learn.

**Список литературы**
1. Тихонов А. Н., Гончарский А. В., Степанов В.В., Ягола А. Г. Регуляризирующие алгоритмы и априорная информация. – М.: Наука, 1983. – 200 с.
